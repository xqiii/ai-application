# Agent

## 什么是Agent

Agent是一个具有自主决策能力的系统，它能够根据环境信息和任务目标，自主地进行决策和行动。

## Agent的组成

Agent的组成包括：

- 感知模块：感知模块是Agent的感知器官，它能够感知环境信息，并将其转化为Agent可以理解的信息。
- 决策模块：决策模块是Agent的决策器官，它能够根据环境信息和任务目标，自主地进行决策和行动。
- 执行模块：执行模块是Agent的执行器官，它能够根据决策模块的决策，自主地进行行动。

## Agent设计模式

### COT（Chain of Thought）

引导大语言模型（LLM）在给出最终答案之前，先生成一系列中间的推理步骤。

- 传统模式：输入问题 -> 模型直接输出答案。（容易在处理复杂逻辑时出错，产生“幻觉”）
- CoT 模式：输入问题 -> 模型输出“第一步...第二步...因为...所以...” -> 得出最终答案。

在 Agent 中，CoT 的每一步不仅可以是文字推理，还可以是行动指令。
- 思考步骤 1：我需要知道今天的天气。 -> 行动：调用天气 API。
- 思考步骤 2：API 返回下雨。 -> 推理：下雨不适合去公园。
- 思考步骤 3：我需要寻找室内替代方案。 -> 行动：搜索附近的博物馆。


### ReAct（Reasoning Action）

让 AI 学会“边想边做，做了再想”。它将大语言模型的推理能力（Reasoning）与行动能力（Action，如调用工具、搜索网络、执行代码）紧密结合在一个统一的框架中。

核心逻辑：

1. 思考 (Thought)：分析当前情况，决定下一步该做什么，或者根据上一步的行动结果进行推理。
2. 行动 (Action)：根据思考的结果，调用具体的工具（例如：搜索谷歌、查询数据库、运行Python代码、点击按钮）。
3. 观察 (Observation)：获取行动产生的反馈结果（例如：搜索结果页面、代码运行输出、API返回数据）。

### Reflexion

Reflexion 就是让 AI 在“做完之后”复盘总结，将失败的经验或成功的技巧转化为“记忆”，从而在下一次尝试中表现得更好。

核心逻辑：
1. 执行轨迹（Trajectory）：Agent 先尝试完成任务，生成一系列的行动和观察记录。
2. 评估（Evaluation）：系统判断任务是否成功（通过单元测试、用户反馈或奖励模型）。
3. 反思（Reflection）：这是关键一步。如果失败，LLM 会被要求分析整个轨迹，找出错误根源，并生成一段自然语言形式的“反思文本”（Self-Reflection）。
- 例如：“我刚才失败是因为在调用搜索 API 时没有指定时间范围，导致结果过时。下次我应该先获取当前日期，并在搜索词中加入年份限制。”
4. 记忆增强（Augmentation）：将这段“反思文本”存入 Agent 的短期或长期记忆中。
5. 重新尝试（Retry）：Agent 带着这段新的“经验记忆”重新开始任务。由于有了之前的教训，它极大概率会避开之前的坑，采用更优的策略。